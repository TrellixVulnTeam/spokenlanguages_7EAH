{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from load_data import *\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio, display\n",
    "from librosa.display import specshow\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "audio_file_list = load_csv()\n",
    "sigs, srs, labels = process_audio_files(N=30)\n",
    "S = create_grams(sigs, srs, gram_type=\"spectrograms\", normalize = False, verbose = False)\n",
    "C = create_grams(sigs, srs, gram_type=\"chromagrams\", normalize = True, verbose = False)\n",
    "\n",
    "label_set = set(labels)\n",
    "for i, (sig, label) in enumerate(zip(sigs, labels)):\n",
    "    if label in label_set:\n",
    "        print(i, sig.shape, label)\n",
    "        display(Audio(os.path.join(\"data\", \"trainingset\", audio_file_list[i][0])))\n",
    "        label_set.remove(label)\n",
    "        plt.figure(figsize=(14, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        specshow(np.log10(S[i]), x_axis='time', sr=44100, hop_length=512, y_axis='mel')\n",
    "        plt.set_cmap(\"coolwarm\")\n",
    "        plt.xlabel('Time (seconds)')\n",
    "        plt.subplot(1, 2, 2)\n",
    "        specshow(C[i], x_axis='time', sr=44100, hop_length=512, y_axis='chroma')\n",
    "        plt.set_cmap(\"coolwarm\")\n",
    "        plt.xlabel('Time (seconds)')\n",
    "        yticks = plt.gca().get_yticks()[::12]\n",
    "        plt.gca().set_yticks(yticks)\n",
    "        plt.show()\n",
    "    if len(label_set) == 0: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from sputils import *\n",
    "from models import *\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def transform(tensor, model = \"cnn\"):\n",
    "    if model == \"cnn\":\n",
    "        return(Variable(tensor.unsqueeze(1)))\n",
    "    elif model == \"resnet\":\n",
    "        return(Variable(torch.stack([tensor, tensor, tensor], dim=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed\n",
    "torch.manual_seed(1111)\n",
    "\n",
    "gtype = \"spectrograms\"\n",
    "inputs, labels = get_grams(use_chromagrams = False, N = 100,\n",
    "                           window_size = 2048, freq_bands = 224,\n",
    "                           filelist = \"data/testingset.csv\")\n",
    "\n",
    "# encode labels\n",
    "le = LabelEncoder()\n",
    "le.fit(spconfig.lang_classes)\n",
    "num_targets = le.classes_.shape[0]\n",
    "labels_encoded = le.transform(labels)\n",
    "print(le.classes_)\n",
    "\n",
    "\n",
    "# Create Network\n",
    "model_path = \"output/states/resnet_model_spectrograms_82.pt\"\n",
    "nn_builder = resnet.resnetX\n",
    "nnargs = {}\n",
    "net = nn_builder(num_classes=num_targets, **nnargs)\n",
    "net.load_state_dict(torch.load(model_path))\n",
    "net.eval()\n",
    "#print(net)\n",
    "\n",
    "# make predictions in batches\n",
    "output = []\n",
    "inputs = torch.from_numpy(inputs).float()\n",
    "labels_encoded = torch.from_numpy(labels_encoded[:inputs.size(0)])\n",
    "print(labels_encoded.size())\n",
    "\n",
    "testset = TensorDataset(inputs, labels_encoded)\n",
    "testloader = DataLoader(testset, batch_size=8, shuffle=False)\n",
    "\n",
    "for i, (minibatch, l) in enumerate(testloader):\n",
    "    output += [net(transform(minibatch, \"resnet\")).data]\n",
    "output = torch.cat(output)\n",
    "#output_numpy = nn.functional.softmax(Variable(output)).data.numpy()\n",
    "#np.set_printoptions(formatter={'float': lambda x: \"{0:0.2f}\".format(x)})\n",
    "#print(output_numpy)\n",
    "print(output.max(1)[1].numpy().ravel())\n",
    "yhat = le.inverse_transform(output.max(1)[1].numpy().ravel())\n",
    "#print([(act, pred) for act, pred in zip(labels, yhat)])\n",
    "y_t  = le.inverse_transform(labels_encoded.numpy().ravel())\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "audio_file_list = load_csv(\"/tmp/filelist.csv\")\n",
    "label_set = set(yhat)\n",
    "for i, (sig, label) in enumerate(zip(inputs.numpy(), yhat)):\n",
    "    if label in label_set:\n",
    "        print(i, sig.shape, label)\n",
    "        display(Audio(os.path.join(\"data\", \"testingset\", audio_file_list[i][0])))\n",
    "        label_set.remove(label)\n",
    "        plt.figure(figsize=(14, 5))\n",
    "        sig_plot = sig.copy()\n",
    "        sig_plot += np.abs(sig_plot.min())\n",
    "        sig_plot *= 100\n",
    "        sig_plot += 1e-10\n",
    "        specshow(np.log10(sig_plot), x_axis='time', sr=44100, hop_length=512, y_axis='mel')\n",
    "        plt.set_cmap(\"coolwarm\")\n",
    "        #print(plt.cm.get_cmap().name)\n",
    "        plt.xlabel('Time (seconds)')\n",
    "        plt.show()\n",
    "    if len(label_set) == 0: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
